{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenMIC-2018 baseline model tutorial\n",
    "\n",
    "This notebook demonstrates how to replicate a simplified version of the baseline modeling experiment in [(Humphrey, Durand, and McFee, 2018)](http://ismir2018.ircam.fr/doc/pdfs/203_Paper.pdf).\n",
    "\n",
    "First, make sure you [download the dataset](https://zenodo.org/record/1432913#.W6dPeJNKjOR)!\n",
    "\n",
    "We'll load in the pre-computed [VGGish features](https://github.com/tensorflow/models/tree/master/research/audioset) and labels, and fit a [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) model for each of the 20 instrument classes using the pre-defined train-test splits provided in the repository.\n",
    "\n",
    "We'll then evaluate the models we fit, and show how to apply them to new audio signals.\n",
    "\n",
    "This notebook is not meant to demonstrate state-of-the-art performance on instrument recognition.  Rather, we hope that it can serve as a starting point for building your own instrument detectors without too much effort!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These dependencies are necessary for loading the data\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Be sure to set this after downloading the dataset!\n",
    "DATA_ROOT = 'openmic-2018/'\n",
    "\n",
    "if not os.path.exists(DATA_ROOT):\n",
    "    raise ValueError('Did you forget to set `DATA_ROOT`?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The openmic data is provided in a python-friendly format as `openmic-2018.npz`.\n",
    "\n",
    "You can load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENMIC = np.load(os.path.join(DATA_ROOT, 'openmic-2018.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X', 'Y_true', 'Y_mask', 'sample_key']\n"
     ]
    }
   ],
   "source": [
    "# What's included?\n",
    "print(list(OPENMIC.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's included in the data?\n",
    "\n",
    "- `X`: 20000 * 10 * 128 array of VGGish features\n",
    "    - First index (0..19999) corresponds to the sample key\n",
    "    - Second index (0..9) corresponds to the time within the clip (each time slice is 960 ms long)\n",
    "    - Third index (0..127) corresponds to the VGGish features at each point in the 10sec clip\n",
    "    - Example `X[40, 8]` is the 128-dimensional feature vector for the 9th time slice in the 41st example\n",
    "- `Y_true`: 20000 * 20 array of *true* label probabilities\n",
    "    - First index corresponds to sample key, as above\n",
    "    - Second index corresponds to the label class (accordion, ..., voice)\n",
    "    - Example: `Y[40, 4]` indicates the confidence that example #41 contains the 5th instrument\n",
    "- `Y_mask`: 20000 * 20 binary mask values\n",
    "    - First index corresponds to sample key\n",
    "    - Second index corresponds to the label class\n",
    "    - Example: `Y[40, 4]` indicates whether or not we have observations for the 5th instrument for example #41\n",
    "- `sample_key`: 20000 array of sample key strings\n",
    "    - Example: `sample_key[40]` is the sample key for example #41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be easier to use if we make direct variable names for everything\n",
    "X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192,  30, 176, 126, 208,  85,  84,  95,  69, 234,  99, 118, 166,\n",
       "       150, 106,  68, 165, 156, 146, 206,  75, 210, 131,  49,  61, 218,\n",
       "        92, 152, 121, 167,  62, 166, 167, 237,  22, 168, 165, 137, 178,\n",
       "       132, 196,  96,  54, 166, 169, 132,  59,  27,  46, 123,  89,  47,\n",
       "        58, 116,  48, 188, 157,  28,  44, 252, 248, 100,  28, 154, 147,\n",
       "       148, 204, 104,  95,  67, 109, 147, 204, 146, 196, 222,  90, 255,\n",
       "        94, 171,  53, 133, 202, 152,  35,  55, 231, 255,  62, 227, 168,\n",
       "       192,  87, 144, 130, 255,   0,   0, 163,  75, 255, 135, 216,  68,\n",
       "         0, 199,   0, 193, 254, 114,  12, 255,   0,  74, 165,   0, 201,\n",
       "       246,   0, 127, 211, 218, 164,  57, 238, 176, 158, 255], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features for the 9th time slice of 81st example\n",
    "X[80, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.15055, 0.5    ,\n",
       "       0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    ,\n",
       "       0.5    , 0.5    , 0.5    , 0.5    , 0.5    , 0.5    ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_true[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_mask[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000385_249600'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_key[40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the class map\n",
    "\n",
    "For convenience, we provide a simple JSON object that maps class indices to names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_ROOT, 'class-map.json'), 'r') as f:\n",
    "    class_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordion': 0,\n",
       " 'banjo': 1,\n",
       " 'bass': 2,\n",
       " 'cello': 3,\n",
       " 'clarinet': 4,\n",
       " 'cymbals': 5,\n",
       " 'drums': 6,\n",
       " 'flute': 7,\n",
       " 'guitar': 8,\n",
       " 'mallet_percussion': 9,\n",
       " 'mandolin': 10,\n",
       " 'organ': 11,\n",
       " 'piano': 12,\n",
       " 'saxophone': 13,\n",
       " 'synthesizer': 14,\n",
       " 'trombone': 15,\n",
       " 'trumpet': 16,\n",
       " 'ukulele': 17,\n",
       " 'violin': 18,\n",
       " 'voice': 19}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the train-test splits\n",
    "\n",
    "OpenMIC-2018 comes with a pre-defined train-test split.  Great care was taken to ensure that this split is approximately balanced and artists are not represented in both sides of the split, so please use it!\n",
    "\n",
    "This is done by sample key, not row number, so you will need to go through the `sample_key` array to slice the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's split the data into the training and test set\n",
    "# We use squeeze=True here to return a single array for each, rather than a full DataFrame\n",
    "\n",
    "split_train = pd.read_csv(os.path.join(DATA_ROOT, 'partitions/split01_train.csv'), \n",
    "                          header=None, squeeze=True)\n",
    "split_test = pd.read_csv(os.path.join(DATA_ROOT, 'partitions/split01_test.csv'), \n",
    "                         header=None, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      000046_3840\n",
       "1    000135_483840\n",
       "2    000139_119040\n",
       "3    000141_153600\n",
       "4     000144_30720\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These two tables contain the sample keys for training and testing examples\n",
    "# Let's see the keys for the first five training example\n",
    "split_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train: 14915,  # Test: 5085\n"
     ]
    }
   ],
   "source": [
    "# How many train and test examples do we have?  About 75%/25%\n",
    "print('# Train: {},  # Test: {}'.format(len(split_train), len(split_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These sample key maps are easier to use as sets, so let's make them sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set(split_train)\n",
    "test_set = set(split_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "Now that we have the sample keys for the training and testing examples, we need to partition the data arrays (`X`, `Y_true`, `Y_mask`).\n",
    "\n",
    "This is a little delicate to get right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These loops go through all sample keys, and save their row numbers\n",
    "# to either idx_train or idx_test\n",
    "#\n",
    "# This will be useful in the next step for slicing the array data\n",
    "idx_train, idx_test = [], []\n",
    "\n",
    "for idx, n in enumerate(sample_key):\n",
    "    if n in train_set:\n",
    "        idx_train.append(idx)\n",
    "    elif n in test_set:\n",
    "        idx_test.append(idx)\n",
    "    else:\n",
    "        # This should never happen, but better safe than sorry.\n",
    "        raise RuntimeError('Unknown sample key={}! Abort!'.format(sample_key[n]))\n",
    "        \n",
    "# Finally, cast the idx_* arrays to numpy structures\n",
    "idx_train = np.asarray(idx_train)\n",
    "idx_test = np.asarray(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finally, we use the split indices to partition the features, labels, and masks\n",
    "X_train = X[idx_train]\n",
    "X_test = X[idx_test]\n",
    "\n",
    "Y_true_train = Y_true[idx_train]\n",
    "Y_true_test = Y_true[idx_test]\n",
    "\n",
    "Y_mask_train = Y_mask[idx_train]\n",
    "Y_mask_test = Y_mask[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14915, 10, 128)\n",
      "(5085, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "# Print out the sliced shapes as a sanity check\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fit the models\n",
    "\n",
    "Now, we'll iterate over all the instrument classes, and fit a separate `RandomForest` model for each one.\n",
    "\n",
    "For each instrument, the steps are as follows:\n",
    "\n",
    "1. Find the subset of training (and testing) data that have been annotated for the current instrument\n",
    "2. Simplify the features to have one observation point per clip, instead of one point per time slice within each clip\n",
    "3. Initialize a classifier\n",
    "4. Fit the classifier to the training data\n",
    "5. Evaluate the classifier on the test data and print a report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "accordion\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      1.00      0.98      1159\n",
      "        True       1.00      0.88      0.94       374\n",
      "\n",
      "    accuracy                           0.97      1533\n",
      "   macro avg       0.98      0.94      0.96      1533\n",
      "weighted avg       0.97      0.97      0.97      1533\n",
      "\n",
      "True\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.97      0.90       423\n",
      "        True       0.77      0.32      0.45       115\n",
      "\n",
      "    accuracy                           0.83       538\n",
      "   macro avg       0.81      0.65      0.68       538\n",
      "weighted avg       0.83      0.83      0.81       538\n",
      "\n",
      "(538,)\n",
      "(538,)\n",
      "----------------------------------------------------\n",
      "banjo\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.98      0.98      1148\n",
      "        True       0.97      0.97      0.97       592\n",
      "\n",
      "    accuracy                           0.98      1740\n",
      "   macro avg       0.98      0.97      0.98      1740\n",
      "weighted avg       0.98      0.98      0.98      1740\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.90      0.86       338\n",
      "        True       0.68      0.52      0.59       140\n",
      "\n",
      "    accuracy                           0.79       478\n",
      "   macro avg       0.75      0.71      0.72       478\n",
      "weighted avg       0.78      0.79      0.78       478\n",
      "\n",
      "(478,)\n",
      "(478,)\n",
      "----------------------------------------------------\n",
      "bass\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.99      0.98      1010\n",
      "        True       0.96      0.93      0.95       415\n",
      "\n",
      "    accuracy                           0.97      1425\n",
      "   macro avg       0.97      0.96      0.96      1425\n",
      "weighted avg       0.97      0.97      0.97      1425\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.96      0.89       329\n",
      "        True       0.83      0.49      0.61       134\n",
      "\n",
      "    accuracy                           0.82       463\n",
      "   macro avg       0.83      0.72      0.75       463\n",
      "weighted avg       0.82      0.82      0.81       463\n",
      "\n",
      "(463,)\n",
      "(463,)\n",
      "----------------------------------------------------\n",
      "cello\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.97       866\n",
      "        True       0.95      0.98      0.96       598\n",
      "\n",
      "    accuracy                           0.97      1464\n",
      "   macro avg       0.97      0.97      0.97      1464\n",
      "weighted avg       0.97      0.97      0.97      1464\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.83      0.81       259\n",
      "        True       0.79      0.76      0.78       226\n",
      "\n",
      "    accuracy                           0.80       485\n",
      "   macro avg       0.80      0.79      0.79       485\n",
      "weighted avg       0.80      0.80      0.80       485\n",
      "\n",
      "(485,)\n",
      "(485,)\n",
      "----------------------------------------------------\n",
      "clarinet\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      1.00      0.96      1349\n",
      "        True       1.00      0.70      0.82       396\n",
      "\n",
      "    accuracy                           0.93      1745\n",
      "   macro avg       0.96      0.85      0.89      1745\n",
      "weighted avg       0.94      0.93      0.93      1745\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.99      0.88       503\n",
      "        True       0.71      0.09      0.16       137\n",
      "\n",
      "    accuracy                           0.80       640\n",
      "   macro avg       0.75      0.54      0.52       640\n",
      "weighted avg       0.78      0.80      0.73       640\n",
      "\n",
      "(640,)\n",
      "(640,)\n",
      "----------------------------------------------------\n",
      "cymbals\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.90      0.95       485\n",
      "        True       0.94      1.00      0.97       814\n",
      "\n",
      "    accuracy                           0.96      1299\n",
      "   macro avg       0.97      0.95      0.96      1299\n",
      "weighted avg       0.97      0.96      0.96      1299\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.85      0.90       139\n",
      "        True       0.93      0.98      0.96       297\n",
      "\n",
      "    accuracy                           0.94       436\n",
      "   macro avg       0.94      0.91      0.93       436\n",
      "weighted avg       0.94      0.94      0.94       436\n",
      "\n",
      "(436,)\n",
      "(436,)\n",
      "----------------------------------------------------\n",
      "drums\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.95      0.98       495\n",
      "        True       0.97      1.00      0.99       828\n",
      "\n",
      "    accuracy                           0.98      1323\n",
      "   macro avg       0.99      0.98      0.98      1323\n",
      "weighted avg       0.98      0.98      0.98      1323\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.79      0.86       146\n",
      "        True       0.90      0.97      0.93       278\n",
      "\n",
      "    accuracy                           0.91       424\n",
      "   macro avg       0.91      0.88      0.89       424\n",
      "weighted avg       0.91      0.91      0.91       424\n",
      "\n",
      "(424,)\n",
      "(424,)\n",
      "----------------------------------------------------\n",
      "flute\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.99      0.98      1050\n",
      "        True       0.98      0.94      0.96       472\n",
      "\n",
      "    accuracy                           0.98      1522\n",
      "   macro avg       0.98      0.97      0.97      1522\n",
      "weighted avg       0.98      0.98      0.98      1522\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.91      0.83       387\n",
      "        True       0.65      0.37      0.47       175\n",
      "\n",
      "    accuracy                           0.74       562\n",
      "   macro avg       0.71      0.64      0.65       562\n",
      "weighted avg       0.73      0.74      0.72       562\n",
      "\n",
      "(562,)\n",
      "(562,)\n",
      "----------------------------------------------------\n",
      "guitar\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.95      0.98       362\n",
      "        True       0.98      1.00      0.99       852\n",
      "\n",
      "    accuracy                           0.99      1214\n",
      "   macro avg       0.99      0.98      0.98      1214\n",
      "weighted avg       0.99      0.99      0.99      1214\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.97      0.97       150\n",
      "        True       0.98      0.98      0.98       286\n",
      "\n",
      "    accuracy                           0.98       436\n",
      "   macro avg       0.97      0.97      0.97       436\n",
      "weighted avg       0.98      0.98      0.98       436\n",
      "\n",
      "(436,)\n",
      "(436,)\n",
      "----------------------------------------------------\n",
      "mallet_percussion\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.95      0.97       802\n",
      "        True       0.93      1.00      0.96       522\n",
      "\n",
      "    accuracy                           0.97      1324\n",
      "   macro avg       0.96      0.97      0.97      1324\n",
      "weighted avg       0.97      0.97      0.97      1324\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.84      0.81       267\n",
      "        True       0.78      0.69      0.73       211\n",
      "\n",
      "    accuracy                           0.77       478\n",
      "   macro avg       0.77      0.76      0.77       478\n",
      "weighted avg       0.77      0.77      0.77       478\n",
      "\n",
      "(478,)\n",
      "(478,)\n",
      "----------------------------------------------------\n",
      "mandolin\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.96      0.97      1185\n",
      "        True       0.93      0.95      0.94       652\n",
      "\n",
      "    accuracy                           0.96      1837\n",
      "   macro avg       0.95      0.96      0.95      1837\n",
      "weighted avg       0.96      0.96      0.96      1837\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.83      0.82       434\n",
      "        True       0.59      0.57      0.58       193\n",
      "\n",
      "    accuracy                           0.75       627\n",
      "   macro avg       0.70      0.70      0.70       627\n",
      "weighted avg       0.75      0.75      0.75       627\n",
      "\n",
      "(627,)\n",
      "(627,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "organ\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98       977\n",
      "        True       1.00      0.93      0.96       482\n",
      "\n",
      "    accuracy                           0.98      1459\n",
      "   macro avg       0.98      0.96      0.97      1459\n",
      "weighted avg       0.98      0.98      0.98      1459\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.95      0.85       310\n",
      "        True       0.67      0.25      0.36       121\n",
      "\n",
      "    accuracy                           0.75       431\n",
      "   macro avg       0.72      0.60      0.60       431\n",
      "weighted avg       0.74      0.75      0.71       431\n",
      "\n",
      "(431,)\n",
      "(431,)\n",
      "----------------------------------------------------\n",
      "piano\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.96      0.98       420\n",
      "        True       0.98      1.00      0.99       885\n",
      "\n",
      "    accuracy                           0.99      1305\n",
      "   macro avg       0.99      0.98      0.99      1305\n",
      "weighted avg       0.99      0.99      0.99      1305\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.85      0.90       130\n",
      "        True       0.93      0.98      0.96       285\n",
      "\n",
      "    accuracy                           0.94       415\n",
      "   macro avg       0.94      0.91      0.93       415\n",
      "weighted avg       0.94      0.94      0.94       415\n",
      "\n",
      "(415,)\n",
      "(415,)\n",
      "----------------------------------------------------\n",
      "saxophone\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.94      0.97       906\n",
      "        True       0.94      0.99      0.96       830\n",
      "\n",
      "    accuracy                           0.96      1736\n",
      "   macro avg       0.97      0.97      0.96      1736\n",
      "weighted avg       0.97      0.96      0.96      1736\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.80      0.83       324\n",
      "        True       0.80      0.86      0.83       305\n",
      "\n",
      "    accuracy                           0.83       629\n",
      "   macro avg       0.83      0.83      0.83       629\n",
      "weighted avg       0.83      0.83      0.83       629\n",
      "\n",
      "(629,)\n",
      "(629,)\n",
      "----------------------------------------------------\n",
      "synthesizer\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.95      0.97       399\n",
      "        True       0.98      1.00      0.99       823\n",
      "\n",
      "    accuracy                           0.98      1222\n",
      "   macro avg       0.99      0.98      0.98      1222\n",
      "weighted avg       0.98      0.98      0.98      1222\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.90      0.92       112\n",
      "        True       0.96      0.97      0.97       268\n",
      "\n",
      "    accuracy                           0.95       380\n",
      "   macro avg       0.95      0.94      0.94       380\n",
      "weighted avg       0.95      0.95      0.95       380\n",
      "\n",
      "(380,)\n",
      "(380,)\n",
      "----------------------------------------------------\n",
      "trombone\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.98      0.97      1405\n",
      "        True       0.95      0.89      0.92       635\n",
      "\n",
      "    accuracy                           0.95      2040\n",
      "   macro avg       0.95      0.94      0.94      2040\n",
      "weighted avg       0.95      0.95      0.95      2040\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.92      0.87       492\n",
      "        True       0.77      0.54      0.63       228\n",
      "\n",
      "    accuracy                           0.80       720\n",
      "   macro avg       0.79      0.73      0.75       720\n",
      "weighted avg       0.80      0.80      0.79       720\n",
      "\n",
      "(720,)\n",
      "(720,)\n",
      "----------------------------------------------------\n",
      "trumpet\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.97      0.97      1303\n",
      "        True       0.96      0.95      0.95       828\n",
      "\n",
      "    accuracy                           0.96      2131\n",
      "   macro avg       0.96      0.96      0.96      2131\n",
      "weighted avg       0.96      0.96      0.96      2131\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.88      0.82       467\n",
      "        True       0.78      0.62      0.69       318\n",
      "\n",
      "    accuracy                           0.78       785\n",
      "   macro avg       0.78      0.75      0.76       785\n",
      "weighted avg       0.78      0.78      0.77       785\n",
      "\n",
      "(785,)\n",
      "(785,)\n",
      "----------------------------------------------------\n",
      "ukulele\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.98      0.98      1279\n",
      "        True       0.96      0.93      0.94       556\n",
      "\n",
      "    accuracy                           0.97      1835\n",
      "   macro avg       0.96      0.95      0.96      1835\n",
      "weighted avg       0.97      0.97      0.96      1835\n",
      "\n",
      "True\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.88      0.84       408\n",
      "        True       0.67      0.54      0.60       182\n",
      "\n",
      "    accuracy                           0.78       590\n",
      "   macro avg       0.74      0.71      0.72       590\n",
      "weighted avg       0.77      0.78      0.77       590\n",
      "\n",
      "(590,)\n",
      "(590,)\n",
      "----------------------------------------------------\n",
      "violin\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.88      0.94       623\n",
      "        True       0.91      1.00      0.95       779\n",
      "\n",
      "    accuracy                           0.95      1402\n",
      "   macro avg       0.96      0.94      0.94      1402\n",
      "weighted avg       0.95      0.95      0.95      1402\n",
      "\n",
      "False\n",
      "False\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.70      0.78       237\n",
      "        True       0.84      0.94      0.88       394\n",
      "\n",
      "    accuracy                           0.85       631\n",
      "   macro avg       0.85      0.82      0.83       631\n",
      "weighted avg       0.85      0.85      0.84       631\n",
      "\n",
      "(631,)\n",
      "(631,)\n",
      "----------------------------------------------------\n",
      "voice\n",
      "\tTRAIN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.91      0.95       426\n",
      "        True       0.95      1.00      0.98       764\n",
      "\n",
      "    accuracy                           0.97      1190\n",
      "   macro avg       0.97      0.95      0.96      1190\n",
      "weighted avg       0.97      0.97      0.97      1190\n",
      "\n",
      "True\n",
      "True\n",
      "\tTEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.89      0.91       150\n",
      "        True       0.93      0.96      0.94       224\n",
      "\n",
      "    accuracy                           0.93       374\n",
      "   macro avg       0.93      0.92      0.93       374\n",
      "weighted avg       0.93      0.93      0.93       374\n",
      "\n",
      "(374,)\n",
      "(374,)\n"
     ]
    }
   ],
   "source": [
    "# This dictionary will include the classifiers for each model\n",
    "models = dict()\n",
    "\n",
    "# We'll iterate over all istrument classes, and fit a model for each one\n",
    "# After training, we'll print a classification report for each instrument\n",
    "for instrument in class_map:\n",
    "    \n",
    "    # Map the instrument name to its column number\n",
    "    inst_num = class_map[instrument]\n",
    "        \n",
    "    # Step 1: sub-sample the data\n",
    "    \n",
    "    # First, we need to select down to the data for which we have annotations\n",
    "    # This is what the mask arrays are for\n",
    "    train_inst = Y_mask_train[:, inst_num]\n",
    "    test_inst = Y_mask_test[:, inst_num]\n",
    "    \n",
    "    # Here, we're using the Y_mask_train array to slice out only the training examples\n",
    "    # for which we have annotations for the given class\n",
    "    X_train_inst = X_train[train_inst]\n",
    "    \n",
    "    # Step 3: simplify the data by averaging over time\n",
    "    \n",
    "    # Let's arrange the data for a sklearn Random Forest model \n",
    "    # Instead of having time-varying features, we'll summarize each track by its mean feature vector over time\n",
    "    X_train_inst_sklearn = np.mean(X_train_inst, axis=1)\n",
    "    \n",
    "    # Again, we slice the labels to the annotated examples\n",
    "    # We thresold the label likelihoods at 0.5 to get binary labels\n",
    "    Y_true_train_inst = Y_true_train[train_inst, inst_num] >= 0.5\n",
    "\n",
    "    \n",
    "    # Repeat the above slicing and dicing but for the test set\n",
    "    X_test_inst = X_test[test_inst]\n",
    "    X_test_inst_sklearn = np.mean(X_test_inst, axis=1)\n",
    "    Y_true_test_inst = Y_true_test[test_inst, inst_num] >= 0.5\n",
    "\n",
    "    # Step 3.\n",
    "    # Initialize a new classifier\n",
    "    clf = RandomForestClassifier(max_depth=8, n_estimators=100, random_state=0)\n",
    "    \n",
    "    # Step 4.\n",
    "    clf.fit(X_train_inst_sklearn, Y_true_train_inst)\n",
    "\n",
    "    # Step 5.\n",
    "    # Finally, we'll evaluate the model on both train and test\n",
    "    Y_pred_train = clf.predict(X_train_inst_sklearn)\n",
    "    Y_pred_test = clf.predict(X_test_inst_sklearn)\n",
    "    \n",
    "    print('-' * 52)\n",
    "    print(instrument)\n",
    "    print('\\tTRAIN')\n",
    "    print(classification_report(Y_true_train_inst, Y_pred_train))\n",
    "    print(Y_true_train_inst[3])\n",
    "    print(Y_pred_train[3])\n",
    "    print('\\tTEST')\n",
    "    print(classification_report(Y_true_test_inst, Y_pred_test))\n",
    "    \n",
    "    print(Y_true_test_inst.shape)\n",
    "    print(Y_pred_test.shape)\n",
    "    \n",
    "    # Store the classifier in our dictionary\n",
    "    models[instrument] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the model to new data\n",
    "\n",
    "In this section, we'll take the models trained above and apply them to audio signals, stored as OGG Vorbis files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'soundfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-51bf03974dcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# We need soundfile to load audio data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# And the openmic-vggish preprocessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopenmic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvggish\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'soundfile'"
     ]
    }
   ],
   "source": [
    "# We need soundfile to load audio data\n",
    "import soundfile as sf\n",
    "\n",
    "# And the openmic-vggish preprocessor\n",
    "import openmic.vggish\n",
    "\n",
    "# For audio playback\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We include a test ogg file in the openmic repository, which we can use here.\n",
    "audio, rate = sf.read(os.path.join(DATA_ROOT, 'audio/000/000046_3840.ogg'))\n",
    "\n",
    "time_points, features = openmic.vggish.waveform_to_features(audio, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The time_points array marks the starting time of each observation\n",
    "time_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features array includes the vggish feature observations\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listen to the example\n",
    "Audio(data=audio.T, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, apply the classifier\n",
    "\n",
    "# Average over time to one observation, but keep the number of dimensions the same\n",
    "# The test clip is 10sec long, so this is the same process as in the training step\n",
    "# However, you could also apply the classifier to each frame independently to get time-varying predictions\n",
    "feature_mean = np.mean(features, axis=0, keepdims=True)\n",
    "\n",
    "for instrument in models:\n",
    "    \n",
    "    clf = models[instrument]\n",
    "    \n",
    "    print('P[{:18s}=1] = {:.3f}'.format(instrument, clf.predict_proba(feature_mean)[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up\n",
    "\n",
    "So the predictions here are definitely not perfect, but they're a good start!\n",
    "\n",
    "Some things you might want to try out:\n",
    "\n",
    "1. Instead of averaging features over time, apply the classifiers to each time-step to get a time-varying instrument detector.\n",
    "2. Play with the parameters of the `RandomForest` model, changing the depth and number of estimators.\n",
    "3. Run the trained model on your own favorite songs!\n",
    "4. Train a different model, maybe using different features!\n",
    "5. Make use of label uncertainties or unlabeled data when training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
