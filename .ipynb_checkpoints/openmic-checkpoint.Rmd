---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.3.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
import librosa as lb
import librosa.display
import pandas as pd
import scipy
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split
import os
from pylab import plot, show, figure, imshow, xlim, ylim, title
import matplotlib.pyplot as plt
import keras
from keras.utils import np_utils
from keras import layers
from keras import modelsasdasdasd
```

```{python}
#CONSTANTS

DATA_DIR = "openmic-2018/"
CATEGORY_COUNT = 8
```

```{python}
df = pd.read_csv('openmic-2018/openmic-2018-aggregated-labels.csv')
del df['relevance']
del df['num_responses']
```

```{python}
labels = df.values
labels
```

```{python}
y, sr = lb.load(DATA_DIR + 'audio/000/000135_483840.ogg')
S = lb.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)

S_dB = lb.power_to_db(S, ref=np.max) # 10 * log10(S / ref)

```

```{python}
librosa.display.specshow(S_dB, x_axis='s', y_axis='mel')
plt.colorbar(format='%+2.0f dB')
```

```{python}
OPENMIC = np.load(os.path.join(DATA_DIR, 'openmic-2018.npz'), allow_pickle=True)
print(list(OPENMIC.keys()))
```

```{python}
X, Y_true, Y_mask, sample_key = OPENMIC['X'], OPENMIC['Y_true'], OPENMIC['Y_mask'], OPENMIC['sample_key']
```

```{python}
X[0][0][0]
```
